2. Theoretische Grundlagen
2.1 Zieldefinierung KPIs

Key Performance Indicators (KPIs) sind zentrale Steuerungsinstrumente des Performance Managements. Sie dienen der Messung strategischer wie operativer Zielerreichung und stellen sicher, dass Abweichungen frÃ¼hzeitig erkannt und korrigiert werden kÃ¶nnen.Â¹ Eine prÃ¤zise Zieldefinition bildet den Grundstein fÃ¼r die Aussagekraft der Kennzahlen, da unscharfe oder unklare ZielgrÃ¶ÃŸen keine verlÃ¤sslichen Steuerungsimpulse liefern.Â²

Als etabliertes Prinzip gilt die SMART-Formel: Ziele sollten spezifisch, messbar, attraktiv, realistisch und terminiert sein.Â³ Diese Kriterien garantieren, dass KPI-Werte eindeutig interpretierbar sind, motivierend wirken und innerhalb vorhandener Ressourcen erreichbar bleiben. Die Terminvorgabe verhindert zudem eine schleichende Entwertung der Indikatoren.

In der Praxis erfolgt die Auswahl geeigneter KPIs im Einklang mit der Unternehmensstrategie. WÃ¤hrend finanzielle, prozessuale und kundenorientierte Kennzahlen unterschiedliche Schwerpunkte setzen, empfiehlt die Balanced Scorecard einen balancierten Ansatz Ã¼ber mehrere Dimensionen.â´ ErgÃ¤nzend zeigt das Performance Prism, dass Stakeholder-Perspektiven stÃ¤rker integriert werden mÃ¼ssen, um eine ganzheitliche Steuerung sicherzustellen.âµ

KPIs sind nicht statisch, sondern Teil eines kontinuierlichen Verbesserungsprozesses. Sie werden regelmÃ¤ÃŸig Ã¼berprÃ¼ft und an neue Markt- oder Unternehmensbedingungen angepasst. In diesem Zusammenhang spielt auch das QualitÃ¤tsmanagement (z. B. ISO 9001) eine Rolle, das Kennzahlen als integralen Bestandteil des PDCA-Zyklus versteht.â¶

2.2 Abweichungsanalyse

Die Abweichungsanalyse â€“ hÃ¤ufig in Form von Soll-Ist-Vergleichen â€“ bildet die methodische Grundlage zur Identifikation von Optimierungspotenzialen in GeschÃ¤ftsprozessen.â· Dabei wird der aktuelle Zustand detailliert erfasst und einem definierten Soll-Zustand gegenÃ¼bergestellt. Diese GegenÃ¼berstellung offenbart LÃ¼cken, die systematisch analysiert und priorisiert werden.

Die Ist-Analyse erfolgt auf Basis von Organisationsdokumenten, IT-Systemprotokollen oder Interviews mit Fachpersonal.â¸ Ziel ist ein objektives Abbild der RealitÃ¤t, das als Grundlage fÃ¼r die Modellierung des Soll-Zustands dient. Dieser wird mithilfe standardisierter Modellierungssprachen wie BPMN formal beschrieben und unterstÃ¼tzt die Kommunikation zwischen Stakeholdern.â¹

Der Soll-Ist-Vergleich (auch Gap-Analyse) priorisiert Abweichungen anhand von Kriterien wie Dringlichkeit, KomplexitÃ¤t oder Nutzenpotenzial.Â¹â° Gerade in Transformationsprojekten ist diese Methode unverzichtbar, um Investitionen in IT-Systeme und Prozesse zu rechtfertigen und die Akzeptanz der Beteiligten zu erhÃ¶hen.

Gleichzeitig weist die Literatur auf Herausforderungen hin: DatenlÃ¼cken, heterogene Systemlandschaften und kulturelle WiderstÃ¤nde kÃ¶nnen die Analyse erschweren.Â¹Â¹ Nur durch interdisziplinÃ¤re Projektteams, iterative Vorgehensweisen und transparente Kommunikation kann die Abweichungsanalyse ihr volles Potenzial entfalten.

2.3 Ursachenforschung
5-Why-Methode

Die 5-Why-Methode wurde im Toyota-Produktionssystem entwickelt und dient dazu, durch wiederholtes Nachfragen nach dem â€Warum?â€œ von oberflÃ¤chlichen Symptomen zu tieferliegenden Ursachen vorzudringen.Â¹Â² In der Regel reichen fÃ¼nf Wiederholungen aus, um die Grundursache eines Problems zu identifizieren. Praktisch wird der Analyseprozess in interdisziplinÃ¤ren Teams durchgefÃ¼hrt, die ihre Antworten sequenziell dokumentieren.Â¹Â³

Die Methode Ã¼berzeugt durch Einfachheit und schnelle Anwendbarkeit. Nachteile bestehen darin, dass ohne erfahrene Moderation Ursachenketten vorschnell abgebrochen werden kÃ¶nnen.Â¹â´ Deshalb wird empfohlen, die 5-Why-Technik mit anderen Methoden â€“ etwa dem Ishikawa-Diagramm â€“ zu kombinieren.

Fishbone-Diagramm

Das Fishbone-Diagramm, auch als Ishikawa- oder Ursache-Wirkungs-Diagramm bekannt, wurde in den 1960er Jahren entwickelt und zÃ¤hlt zu den â€Sieben QualitÃ¤tstechnikenâ€œ.Â¹âµ Die visuelle Darstellung Ã¤hnelt einem Fischskelett, wobei die Hauptursachen in Kategorien wie Mensch, Maschine, Material, Methode, Milieu und Messung (6M) geordnet werden.

Seine StÃ¤rke liegt in der strukturierten und interdisziplinÃ¤ren Ursachenfindung. Typischerweise werden Brainstormings genutzt, um mÃ¶gliche Faktoren zu sammeln und den Kategorien zuzuordnen.Â¹â¶ Studien zeigen, dass die Methode nicht nur Ursachen aufdeckt, sondern auch Teamkommunikation und systematisches Denken fÃ¶rdert.Â¹â·

Pareto-Diagramm

Das Pareto-Diagramm ist ein zentrales Werkzeug der QualitÃ¤ts- und Prozessanalyse. Es ordnet Ursachen absteigend nach ihrem Beitrag und visualisiert diese mit Balkendiagramm und kumulativer Kurve.Â¹â¸ Grundlage ist das Pareto-Prinzip, wonach wenige Ursachen fÃ¼r den GroÃŸteil der Probleme verantwortlich sind (80/20-Regel).Â¹â¹

Der Ablauf umfasst die Definition von Kategorien, die Erhebung und Bereinigung von Daten sowie die Sortierung nach Wirkung. AnschlieÃŸend wird eine kumulative Kurve eingezeichnet, die die wichtigsten Ursachen sichtbar macht.Â²â° In der Logistik kÃ¶nnen z. B. VerzÃ¶gerungen, Rework oder SLA-VerstÃ¶ÃŸe so priorisiert und anschlieÃŸend mit Methoden wie 5-Why oder Ishikawa vertieft werden.Â²Â¹

2.4 Auswirkungsbewertung
Kosten-Nutzen-Analyse

Die Kosten-Nutzen-Analyse (KNA) ist ein klassisches Verfahren der Entscheidungstheorie. Ziel ist es, sÃ¤mtliche Kosten und Nutzen einer MaÃŸnahme zu erfassen, zu monetarisieren und vergleichbar zu machen.Â²Â² Dabei werden nicht nur finanzielle GrÃ¶ÃŸen, sondern auch qualitative Effekte wie Prozessoptimierung oder Risikoreduktion berÃ¼cksichtigt.Â²Â³

Das methodische Vorgehen gliedert sich in: Definition der Alternativen, Identifikation der Kosten- und Nutzenkategorien, Monetarisierung, Diskontierung sowie Berechnung zentraler Kennzahlen (z. B. Nettonutzen oder Kosten-Nutzen-VerhÃ¤ltnis).Â²â´ In der Logistik wird die KNA hÃ¤ufig fÃ¼r die Bewertung von Digitalisierungsprojekten genutzt.Â²âµ

Kritisch wird angemerkt, dass Ergebnisse stark von Annahmen abhÃ¤ngen und nicht-monetÃ¤re Faktoren (z. B. Mitarbeiterzufriedenheit) schwer erfassbar sind.Â²â¶ Deshalb empfehlen viele Autor*innen eine Kombination mit ergÃ¤nzenden Methoden wie Nutzwert- oder Risikoanalysen.

FMEA

Die Failure Mode and Effects Analysis (FMEA) ist ein systematisches Verfahren zur Identifikation und Bewertung potenzieller Fehlerquellen.Â²â· Ziel ist es, Risiken frÃ¼hzeitig zu erkennen und prÃ¤ventive MaÃŸnahmen einzuleiten. Dabei werden mÃ¶gliche Fehlerarten, deren Ursachen und Auswirkungen erfasst und anhand von Kriterien wie Auftretenswahrscheinlichkeit, Bedeutung und Entdeckungswahrscheinlichkeit bewertet.Â²â¸

Das Ergebnis wird in einer RisikoprioritÃ¤tszahl (RPZ) zusammengefÃ¼hrt, die als Grundlage fÃ¼r MaÃŸnahmenplÃ¤ne dient. Besonders im Produkt- und Prozessmanagement gilt die FMEA als Standardmethode, da sie die VerknÃ¼pfung von technischer Analyse und organisatorischer PrÃ¤vention ermÃ¶glicht.Â²â¹ Neuere Studien zeigen, dass die FMEA zunehmend auch in der Logistik und im IT-Kontext eingesetzt wird, etwa zur Risikobewertung bei Prozessdigitalisierung.Â³â°

ğŸ“Œ FuÃŸnoten (Leviathan-Stil)

1 Kaplan, Norton 1996, S. 21 ff.
2 Neely, Adams, Kennerley 2002, S. 12â€“25.
3 Doran 1981, S. 36.
4 Kaplan, Norton 1996, S. 21 ff.
5 Neely, Adams, Kennerley 2002, S. 12â€“25.
6 Bourne, Kennerley, Franco 2002, S. 305 ff.
7 HorvÃ¡th 2011, S. 410â€“420.
8 Becker, Kugeler, Rosemann 2013, S. 152 ff.
9 Schmelzer, Sesselmann 2013, S. 220â€“230.
10 HorvÃ¡th 2011, S. 421â€“430.
11 Becker, Kugeler, Rosemann 2013, S. 160 ff.
12 Serrat 2009, S. 307.
13 Liker 2004, S. 31 ff.
14 Andersen, Fagerhaug 2006, S. 55.
15 Ishikawa 1982, S. 65â€“70.
16 Stamatis 2003, S. 52â€“55.
17 Ishikawa 1982, S. 70.
18 Montgomery 2013, S. 132â€“140.
19 Juran, De Feo 2010, S. 124 ff.
20 Montgomery 2013, S. 135.
21 Juran, De Feo 2010, S. 125.
22 Boardman et al. 2018, S. 3 ff.
23 Hanley, Barbier 2009, S. 17 ff.
24 Mishan, Quah 2020, S. 45 ff.
25 GÃ¼nther, Krcmar 2018, S. 25â€“37.
26 Boardman et al. 2018, S. 22.
27 Stamatis 2003, S. 45â€“70.
28 Kreimeyer, Lindemann 2011, S. 270.
29 Stamatis 2003, S. 66.
30 Kreimeyer, Lindemann 2011, S. 280.
